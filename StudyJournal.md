**Day 1:**

• Pledged to participate in the 60daysofudacity challenge.

• Finished the first project of the lesson 6, Playing with Remote Tensors.

• Looked for an opportunity to join/host a local meetup.

• Revisited my final project for the lesson 5 to see if I can make any improvement.

---

**Day 2:**

• Watched course videos on remote arithmetic and garbage collection with PySyft (Lesson 6).

• Finished the project "Learn a Simple Linear Model".

(Planning to start reading "The Algorithmic Foundations of Differential Privacy".)

(Also planning to read research papers on Deep Learning with Differential Privacy, and PATE analysis.)

(Going to find virtual meetups or host one since finding some people to have local meetups here seems quite challenging.)

---

**Day 3:**

• Finished Lesson 6: Federated Learning

• Started and finished the second section project: Federated Learning on MNIST—the project description does not give any detailed instruction, so I just decided to stick with MNIST. (GitHub link: https://github.com/wytyang00/private-ai/blob/master/final_projects/Section%202%20-%20Federated%20Learning.ipynb?fbclid=IwAR3TVBHX0CtHIEItuyCu1ucxtLJijX4Sn5ICy7MRcx4XGtgnz9_V09xUXb8)

---

**Day 4:**

• Started Lesson 7: Securing Federated Learning

• Finished the first project of Lesson 7: Federated Learning with a Trusted Aggregator (https://github.com/wytyang00/private-ai/blob/master/Section%203%20-%20Securing%20Federated%20Learning.ipynb?fbclid=IwAR3Fc4FVbuo1gsI4akUooADPifR7jZgrB3TqlFXusr1VVgsrmQUHTRsJo7I)

• Joined a study group with @<u>Abhimanyu</u>, @<u>Bhadresh Savani</u>, @<u>Mukul Kathpalia</u>, and many others!

• Had the first online group meetup with @<u>Abhimanyu</u>, @<u>Bhadresh Savani</u>, @<u>Mukul Kathpalia</u>!

---

**Day 5:**

• Formed a local Korean group with 2 other Koreans (+ and potentially one more in the future)

• Scheduled our first local meetup.

• Trying a different approach—the one Andrew demonstrated—to the first project of Lesson 8: Federated Learning with Trusted Aggregator. (Currently experiencing bugs, but I'll fix it by tomorrow.)

---

**Day 6:**

• Continuing on my second attempt to the Lesson 8's first project: Federated Learning with Trusted Aggregator. Narrowed down where things were going wrong, but still can't grasp exactly why it's happening :(

• Discussed a bit about the study group form with both groups I'm in. Still needs to make decisions before we can submit the forms.

• Watched the lectures about Additive Secret Sharing

---

**Day 7:**

• Helped a local fellow scholar debug his PPO code.

• Watched the intro & demo videos on the Lesson 8's second project: Encrypt, Decrypt, and Add.

• Finished the project—Encrypt, Decrypt, and Add—as well.

---

**Day 8:**

• Went to a DL conference and saw brief or detailed overview of many interesting topics: Graph Neural Networks, Knowledge Distillation, Intuition behind DQN extensions, Relational Learning

• Watched all the videos left in the lesson 8: Securing Federated Learning (Fixed Precision Encoding, Doing it using PySyft, Final Project Description)

---

**Day 9:**

• Went half-way through the final project of section 3. Planning to change the training code so that it encodes the gradients or parameters, encrypt them, share them among workers, and then finally aggregate them in the trusted worker.

• Had a virtual meet-up in which we introduced ourselves, discussed any doubts or questions on the course, and talked about project ideas. (@<u>Shivam Raisharma</u> @<u>nabhanpv</u> @<u>Alejandro Galindo</u> @<u>Dharmendra Choudhary</u> @<u>Alejandro Galindo</u> @<u>Ricardo Pretelt</u> @<u>Ingus Terbets</u> @<u>Droid</u> @<u>Sadmi Bouhafs</u> @<u>souvikb1812</u> @<u>Abhishek Tandon</u>)

---

**Day 10:**

• Finished the final project of Section 3 - Securing Federated Learning. I replaced the trusted aggregator with additive secret shares and fixed precision, and the problem suddenly became clearer and simpler! (Notebook link: https://github.com/wytyang00/private-ai/blob/master/final_projects/Section%203%20-%20Securing%20Federated%20Learning.ipynb)

---

**Day 11:**

• Started on the Lesson 9: Encrypted Deep Learning.

• Learned about the field arithmetic involved in the addition, subtraction, and public multiplication with encrypted shares.

• Implemented a PPO agent in a stock training gym environment.

• Skimmed through the BigBiGANs paper.

---

**Day 12:**

• Began the first project of the lesson 8: Encrypted Deep Learning

• Project: started training both PPO and Rainbow DQN agents in trading gym environments.

---

**Day 13:**

• Finished the Encrypted Database project in lesson 9: Encrypted Deep Learning!

• Applied my Rainbow DQN code in the trading gym environment, and it performed much better than our implementation of a PPO agent! (@jeffrey Lim_2)

---

**Day 14:**

• Finished the lessons from 9.6 through the end of the course!

Now I need to start working on the keystone project. I'm thinking of doing it as a group...

---

**Day 15:**

• Decided to continue with my music generation project: https://github.com/wytyang00/undertale_deltarune_soundtrack_generator

• Searched for ideas & examples of models used for music (or any sequential data) generation. I've found several things I could try: **Professor Forcing**, **Scheduled Sampling**, **PixelRNN**, **PixelCNN++**

• Resources I've found:

  * https://www.youtube.com/watch?v=nA3YOFUCn4U

  * https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173

  * https://arxiv.org/abs/1610.09038

---

**Day 16:**

• Attended a local Korean meet-up in the evening with @Yujin, @jeffrey Lim_2, @GwKim! We introduced ourselves to each other, shared recent activities, and discussed some concepts and projects.

---

**Day 17:**

• Edited part of my code for the Section 3 project, mainly to clarify the steps for updating the global model using the trained local models: (https://github.com/wytyang00/private-ai/blob/master/final_projects/Section%203%20-%20Securing%20Federated%20Learning.ipynb)

• Currently following the walk-through of _Attention Is All You Need_ and a PyTorch implementation of Transformer: (http://nlp.seas.harvard.edu/2018/04/03/attention), (https://github.com/wytyang00/Transformer-Hands-On-Tutorial)
